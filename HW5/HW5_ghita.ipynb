{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from fancyimpute import BiScaler , SoftImpute\n",
    "import copy\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) How many songs are in the training dataset? How many users? Based on the training set, provide summary statistics (mean, median, standard deviation, min, and max) for the rating variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the datasets\n",
    "train_data = pd.read_csv(\"MusicRatingsTrain.csv\")\n",
    "val_data_A = pd.read_csv(\"MusicRatingsValidationA.csv\")\n",
    "val_data_B = pd.read_csv(\"MusicRatingsValidationB.csv\")\n",
    "test_data = pd.read_csv(\"MusicRatingsTest.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>songID</th>\n",
       "      <th>rating</th>\n",
       "      <th>songName</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>778</td>\n",
       "      <td>242</td>\n",
       "      <td>1.494918</td>\n",
       "      <td>Billy Liar</td>\n",
       "      <td>2003</td>\n",
       "      <td>The Decemberists</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1892</td>\n",
       "      <td>673</td>\n",
       "      <td>2.149164</td>\n",
       "      <td>The Big Gundown</td>\n",
       "      <td>2009</td>\n",
       "      <td>The Prodigy</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2403</td>\n",
       "      <td>452</td>\n",
       "      <td>1.494918</td>\n",
       "      <td>Hummer</td>\n",
       "      <td>2007</td>\n",
       "      <td>Foals</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1376</td>\n",
       "      <td>437</td>\n",
       "      <td>1.494918</td>\n",
       "      <td>October Song</td>\n",
       "      <td>2003</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>RnB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1479</td>\n",
       "      <td>192</td>\n",
       "      <td>1.494918</td>\n",
       "      <td>Far Away (Album Version)</td>\n",
       "      <td>2006</td>\n",
       "      <td>Nickelback</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  songID    rating                  songName  year            artist  \\\n",
       "0     778     242  1.494918                Billy Liar  2003  The Decemberists   \n",
       "1    1892     673  2.149164           The Big Gundown  2009       The Prodigy   \n",
       "2    2403     452  1.494918                    Hummer  2007             Foals   \n",
       "3    1376     437  1.494918              October Song  2003     Amy Winehouse   \n",
       "4    1479     192  1.494918  Far Away (Album Version)  2006        Nickelback   \n",
       "\n",
       "        genre  \n",
       "0        Rock  \n",
       "1  Electronic  \n",
       "2        Rock  \n",
       "3         RnB  \n",
       "4        Rock  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizing the structure of the data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:  807 songs in the training dataset. \n",
      " There are  2421 users in the training dataset.\n"
     ]
    }
   ],
   "source": [
    "#counting the nb of songs and users in the training dataset\n",
    "nb_songs = len(train_data[\"songID\"].unique())\n",
    "nb_users = len(train_data[\"userID\"].unique())\n",
    "print(\"There are: \", nb_songs, \"songs in the training dataset. \\n There are \", nb_users, \"users in the training dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    245997.000000\n",
       "mean          1.322631\n",
       "std           0.460886\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           1.494918\n",
       "max           4.768656\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistics on the ratings \n",
    "train_data[\"rating\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Let X denote the “true” and “complete” ratings matrix, i.e., $X_{i,j}$ denotes the expected rating \n",
    "of user i for song j across all users and all songs. We are interested in predicting the values of $X_{i,j}$\n",
    "that correspond to cases where we have not yet observed ratings. Let us first consider the following model:\n",
    "$$X_{i,j} = \\alpha _i + β_j + ϵ_{i,j}$$\n",
    "where $α_i$ is a coefficient that depends only on the particular row i (i.e., user), $β_j$ is a coefficient\n",
    "that depends only on the particular column j (i.e., song), and $ϵ_{i,j}$ is a noise term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:  1953747 parameters in the model considered.\n"
     ]
    }
   ],
   "source": [
    "#computing the number of parameters\n",
    "\n",
    "nb_params = int(nb_songs) * int(nb_users)\n",
    "print(\"There are: \", nb_params, \"parameters in the model considered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:  245997 observation to train the model considered.\n"
     ]
    }
   ],
   "source": [
    "#computing the number of observations \n",
    "\n",
    "nb_obs = len(train_data)\n",
    "print(\"There are: \", nb_obs, \"observation to train the model considered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values in the training dataset: 1707750\n"
     ]
    }
   ],
   "source": [
    "#creating the rating matrices\n",
    "train_data_pivot = train_data.pivot_table(index='userID', columns='songID', values='rating')\n",
    "train_data_array = train_data_pivot.to_numpy()\n",
    "\n",
    "train_data_mask = ~np.isnan(train_data_array)\n",
    "n_missing_values = np.sum(train_data_mask==False)\n",
    "print(f\"\\nNumber of missing values in the training dataset: {n_missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BiScaler] Initial log residual value = 9.840515\n",
      "[BiScaler] Iter 1: log residual = 2.093693, log improvement ratio=7.746821\n",
      "[BiScaler] Iter 2: log residual = 0.473543, log improvement ratio=1.620150\n",
      "[BiScaler] Iter 3: log residual = -0.418028, log improvement ratio=0.891571\n",
      "[BiScaler] Iter 4: log residual = -1.204926, log improvement ratio=0.786898\n",
      "[BiScaler] Iter 5: log residual = -1.940070, log improvement ratio=0.735144\n",
      "[BiScaler] Iter 6: log residual = -2.639589, log improvement ratio=0.699519\n",
      "[BiScaler] Iter 7: log residual = -3.314790, log improvement ratio=0.675201\n",
      "[BiScaler] Iter 8: log residual = -3.973003, log improvement ratio=0.658213\n",
      "[BiScaler] Iter 9: log residual = -4.618484, log improvement ratio=0.645481\n",
      "[BiScaler] Iter 10: log residual = -5.253418, log improvement ratio=0.634934\n",
      "[BiScaler] Iter 11: log residual = -5.878700, log improvement ratio=0.625282\n",
      "[BiScaler] Iter 12: log residual = -6.494471, log improvement ratio=0.615771\n",
      "[BiScaler] Iter 13: log residual = -7.100463, log improvement ratio=0.605992\n",
      "[BiScaler] Iter 14: log residual = -7.696230, log improvement ratio=0.595767\n",
      "[BiScaler] Iter 15: log residual = -8.281297, log improvement ratio=0.585066\n",
      "[BiScaler] Iter 16: log residual = -8.855266, log improvement ratio=0.573969\n",
      "[BiScaler] Iter 17: log residual = -9.417887, log improvement ratio=0.562622\n",
      "[BiScaler] Iter 18: log residual = -9.969102, log improvement ratio=0.551215\n",
      "[BiScaler] Iter 19: log residual = -10.509057, log improvement ratio=0.539955\n",
      "[BiScaler] Iter 20: log residual = -11.038101, log improvement ratio=0.529044\n",
      "[BiScaler] Iter 21: log residual = -11.556762, log improvement ratio=0.518661\n",
      "[BiScaler] Iter 22: log residual = -12.065708, log improvement ratio=0.508947\n",
      "[BiScaler] Iter 23: log residual = -12.565710, log improvement ratio=0.500002\n",
      "[BiScaler] Iter 24: log residual = -13.057590, log improvement ratio=0.491881\n",
      "[BiScaler] Iter 25: log residual = -13.542190, log improvement ratio=0.484600\n",
      "[BiScaler] Iter 26: log residual = -14.020332, log improvement ratio=0.478142\n",
      "[BiScaler] Iter 27: log residual = -14.492798, log improvement ratio=0.472466\n",
      "[BiScaler] Iter 28: log residual = -14.960312, log improvement ratio=0.467514\n",
      "[BiScaler] Iter 29: log residual = -15.423531, log improvement ratio=0.463219\n",
      "[BiScaler] Iter 30: log residual = -15.883040, log improvement ratio=0.459509\n",
      "[BiScaler] Iter 31: log residual = -16.339356, log improvement ratio=0.456316\n",
      "[BiScaler] Iter 32: log residual = -16.792929, log improvement ratio=0.453573\n",
      "[BiScaler] Iter 33: log residual = -17.244147, log improvement ratio=0.451218\n",
      "[BiScaler] Iter 34: log residual = -17.693345, log improvement ratio=0.449198\n",
      "[BiScaler] Iter 35: log residual = -18.140809, log improvement ratio=0.447464\n",
      "[BiScaler] Iter 36: log residual = -18.586783, log improvement ratio=0.445974\n",
      "[BiScaler] Iter 37: log residual = -19.031474, log improvement ratio=0.444691\n",
      "[BiScaler] Iter 38: log residual = -19.475058, log improvement ratio=0.443585\n",
      "[BiScaler] Iter 39: log residual = -19.917687, log improvement ratio=0.442628\n",
      "[BiScaler] Iter 40: log residual = -20.359486, log improvement ratio=0.441800\n",
      "[BiScaler] Iter 41: log residual = -20.800566, log improvement ratio=0.441080\n",
      "[BiScaler] Iter 42: log residual = -21.241019, log improvement ratio=0.440453\n",
      "[BiScaler] Iter 43: log residual = -21.680924, log improvement ratio=0.439905\n",
      "[BiScaler] Iter 44: log residual = -22.120350, log improvement ratio=0.439426\n",
      "[BiScaler] Iter 45: log residual = -22.559355, log improvement ratio=0.439005\n",
      "[BiScaler] Iter 46: log residual = -22.997988, log improvement ratio=0.438634\n",
      "[BiScaler] Iter 47: log residual = -23.436295, log improvement ratio=0.438307\n",
      "[BiScaler] Iter 48: log residual = -23.874312, log improvement ratio=0.438017\n",
      "[BiScaler] Iter 49: log residual = -24.312073, log improvement ratio=0.437761\n",
      "[BiScaler] Iter 50: log residual = -24.749606, log improvement ratio=0.437533\n",
      "[BiScaler] Iter 51: log residual = -25.186936, log improvement ratio=0.437330\n",
      "[BiScaler] Iter 52: log residual = -25.624085, log improvement ratio=0.437149\n",
      "[BiScaler] Iter 53: log residual = -26.061073, log improvement ratio=0.436988\n",
      "[BiScaler] Iter 54: log residual = -26.497916, log improvement ratio=0.436843\n",
      "[BiScaler] Iter 55: log residual = -26.934630, log improvement ratio=0.436714\n",
      "[BiScaler] Iter 56: log residual = -27.371228, log improvement ratio=0.436598\n",
      "[BiScaler] Iter 57: log residual = -27.807721, log improvement ratio=0.436493\n",
      "[BiScaler] Iter 58: log residual = -28.244121, log improvement ratio=0.436400\n",
      "[BiScaler] Iter 59: log residual = -28.680436, log improvement ratio=0.436315\n",
      "[BiScaler] Iter 60: log residual = -29.116675, log improvement ratio=0.436239\n",
      "[BiScaler] Iter 61: log residual = -29.552846, log improvement ratio=0.436171\n",
      "[BiScaler] Iter 62: log residual = -29.988955, log improvement ratio=0.436109\n",
      "[BiScaler] Iter 63: log residual = -30.425009, log improvement ratio=0.436053\n",
      "[BiScaler] Iter 64: log residual = -30.861012, log improvement ratio=0.436003\n",
      "[BiScaler] Iter 65: log residual = -31.296969, log improvement ratio=0.435958\n",
      "[BiScaler] Iter 66: log residual = -31.732886, log improvement ratio=0.435916\n",
      "[BiScaler] Iter 67: log residual = -32.168765, log improvement ratio=0.435879\n",
      "[BiScaler] Iter 68: log residual = -32.604611, log improvement ratio=0.435846\n",
      "[BiScaler] Iter 69: log residual = -33.040426, log improvement ratio=0.435815\n",
      "[BiScaler] Iter 70: log residual = -33.476213, log improvement ratio=0.435788\n",
      "[BiScaler] Iter 71: log residual = -33.911976, log improvement ratio=0.435763\n",
      "[BiScaler] Iter 72: log residual = -34.347716, log improvement ratio=0.435740\n",
      "[BiScaler] Iter 73: log residual = -34.783435, log improvement ratio=0.435719\n",
      "[BiScaler] Iter 74: log residual = -35.219136, log improvement ratio=0.435701\n",
      "[BiScaler] Iter 75: log residual = -35.654820, log improvement ratio=0.435684\n",
      "[BiScaler] Iter 76: log residual = -36.090489, log improvement ratio=0.435668\n",
      "[BiScaler] Iter 77: log residual = -36.526144, log improvement ratio=0.435656\n",
      "[BiScaler] Iter 78: log residual = -36.961786, log improvement ratio=0.435642\n",
      "[BiScaler] Iter 79: log residual = -37.397418, log improvement ratio=0.435631\n",
      "[BiScaler] Iter 80: log residual = -37.833038, log improvement ratio=0.435620\n",
      "[BiScaler] Iter 81: log residual = -38.268649, log improvement ratio=0.435611\n",
      "[BiScaler] Iter 82: log residual = -38.704252, log improvement ratio=0.435603\n",
      "[BiScaler] Iter 83: log residual = -39.139847, log improvement ratio=0.435595\n",
      "[BiScaler] Iter 84: log residual = -39.575436, log improvement ratio=0.435589\n",
      "[BiScaler] Iter 85: log residual = -40.011018, log improvement ratio=0.435582\n",
      "[BiScaler] Iter 86: log residual = -40.446593, log improvement ratio=0.435575\n",
      "[BiScaler] Iter 87: log residual = -40.882163, log improvement ratio=0.435569\n",
      "[BiScaler] Iter 88: log residual = -41.317724, log improvement ratio=0.435562\n",
      "[BiScaler] Iter 89: log residual = -41.753298, log improvement ratio=0.435574\n",
      "[BiScaler] Iter 90: log residual = -42.188848, log improvement ratio=0.435550\n",
      "[BiScaler] Iter 91: log residual = -42.624407, log improvement ratio=0.435559\n",
      "[BiScaler] Iter 92: log residual = -43.059960, log improvement ratio=0.435553\n",
      "[BiScaler] Iter 93: log residual = -43.495497, log improvement ratio=0.435537\n",
      "[BiScaler] Iter 94: log residual = -43.931060, log improvement ratio=0.435563\n",
      "[BiScaler] Iter 95: log residual = -44.366590, log improvement ratio=0.435530\n",
      "[BiScaler] Iter 96: log residual = -44.802125, log improvement ratio=0.435535\n",
      "[BiScaler] Iter 97: log residual = -45.237676, log improvement ratio=0.435551\n",
      "[BiScaler] Iter 98: log residual = -45.673207, log improvement ratio=0.435531\n",
      "[BiScaler] Iter 99: log residual = -46.108730, log improvement ratio=0.435523\n",
      "[BiScaler] Iter 100: log residual = -46.544298, log improvement ratio=0.435568\n"
     ]
    }
   ],
   "source": [
    "#fitting the Biscaler \n",
    "biscaler = BiScaler()\n",
    "train_data_centered = biscaler.fit_transform(train_data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating matrices\n",
    "train_data_centered_zero = copy.copy(train_data_centered)\n",
    "train_data_centered_zero[np.isnan(train_data_centered_zero)] = 0\n",
    "train_data_filled = biscaler.inverse_transform(train_data_centered_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songID</th>\n",
       "      <th>songName</th>\n",
       "      <th>artist</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top1</th>\n",
       "      <td>53</td>\n",
       "      <td>Korg Rhythm Afro</td>\n",
       "      <td>Holy Fuck</td>\n",
       "      <td>2.166508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top2</th>\n",
       "      <td>25</td>\n",
       "      <td>Seven Nation Army</td>\n",
       "      <td>The White Stripes</td>\n",
       "      <td>2.130272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top3</th>\n",
       "      <td>438</td>\n",
       "      <td>Stay Where You Are</td>\n",
       "      <td>Sleater-kinney</td>\n",
       "      <td>2.040191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      songID            songName             artist  mean_rating\n",
       "top1      53    Korg Rhythm Afro          Holy Fuck     2.166508\n",
       "top2      25   Seven Nation Army  The White Stripes     2.130272\n",
       "top3     438  Stay Where You Are     Sleater-kinney     2.040191"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plotting the top 3 songs and 3 artists \n",
    "top_songs = np.argpartition(biscaler.column_means, -3)[-3:][::-1]\n",
    "songs = [train_data[train_data.songID ==song]['songName'].iloc[0] for song in top_songs]\n",
    "artists = [train_data[train_data.songID ==song]['artist'].iloc[0] for song in top_songs]\n",
    "top_songs_artists = pd.DataFrame({\n",
    "    'songID': top_songs,\n",
    "    'songName': [train_data[train_data.songID == song]['songName'].iloc[0] for song in top_songs],\n",
    "    'artist': [train_data[train_data.songID == song]['artist'].iloc[0] for song in top_songs],\n",
    "    'mean_rating': biscaler.column_means[top_songs]\n",
    "}, index = [\"top1\", \"top2\", \"top3\"])\n",
    "\n",
    "top_songs_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Top 1</th>\n",
       "      <td>53</td>\n",
       "      <td>-0.035934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.122080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3</th>\n",
       "      <td>438</td>\n",
       "      <td>-0.116710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  mean_rating\n",
       "Top 1      53    -0.035934\n",
       "Top 2      25     0.122080\n",
       "Top 3     438    -0.116710"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting top 3 users\n",
    "top_users = np.argpartition(biscaler.column_means, -3)[-3:][::-1]\n",
    "table_top_users = pd.DataFrame(columns=['userID', 'mean_rating'], data={'userID': top_users, 'mean_rating': biscaler.row_means[top_users]}, index=['Top 1', 'Top 2', 'Top 3'])\n",
    "table_top_users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2421, 807), (2421, 807))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plotting the metrics \n",
    "\n",
    "def calculate_masked_mae(true_values, predicted_values, mask):\n",
    "    masked_diff = true_values[mask] - predicted_values[mask]\n",
    "    return np.mean(np.abs(masked_diff))\n",
    "\n",
    "def calculate_masked_mse(true_values, predicted_values, mask):\n",
    "    masked_diff = true_values[mask] - predicted_values[mask]\n",
    "    return np.mean(masked_diff ** 2)\n",
    "\n",
    "def calculate_OSR2(model_mse, baseline_mse):\n",
    "    return 1 - model_mse / baseline_mse\n",
    "\n",
    "test_pivot = test_data.pivot_table(index=\"userID\", columns = \"songID\", values = \"rating\", dropna=False)\n",
    "test_pivot = pd.merge(pd.Series(train_data_pivot.index),test_pivot.reset_index(),how='outer',on='userID').set_index('userID')\n",
    "test_matrix = test_pivot.to_numpy()\n",
    "\n",
    "test_matrix_mask =  ~np.isnan(test_matrix)\n",
    "np.sum(test_matrix_mask)\n",
    "test_matrix_mask.shape, test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2421, 807)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the matrices\n",
    "mat_centered_0 = copy.copy(train_data_centered)\n",
    "mat_centered_0[np.isnan(mat_centered_0)]=0\n",
    "matrx_filled = biscaler.inverse_transform(mat_centered_0)\n",
    "\n",
    "matrx_filled = biscaler.inverse_transform(mat_centered_0)\n",
    "matrx_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biscale MAE 0.29868140372347 \n",
      "Biscale RMSE 0.39300653381998196 \n",
      "Biscale normalized MAE 0.0746703509308675 \n",
      "Biscale normalized RMSE 0.09825163345499549 \n",
      "Biscale R2 0.28718485726354515\n"
     ]
    }
   ],
   "source": [
    "test_mae = calculate_masked_mae(test_matrix, matrx_filled, test_matrix_mask)\n",
    "print(\"Biscale MAE %s \" % (test_mae)) \n",
    "\n",
    "test_mse = calculate_masked_mse(test_matrix, matrx_filled, test_matrix_mask)\n",
    "print(\"Biscale RMSE %s \" % (np.sqrt(test_mse)))\n",
    "\n",
    "print(\"Biscale normalized MAE %s \" % (test_mae/4)) #Note that we normalize MAE and RMSE by the scale of the ratings, which is 5-(1)=4.\n",
    "print(\"Biscale normalized RMSE %s \" % (np.sqrt(test_mse)/4))\n",
    "\n",
    "baseline_pred = np.mean(train_data.rating)\n",
    "baseline_model = baseline_pred*np.ones((nb_users, nb_songs))\n",
    "baseline_mse = calculate_masked_mse(test_matrix, baseline_model,test_matrix_mask)\n",
    "print(\"Biscale R2 %s\" % calculate_OSR2(test_mse, baseline_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are k* 3228 + 1953747 parameters in this new model. \n",
      "The exact number depends on k.\n",
      "We still have 245997 observations to train this model\n"
     ]
    }
   ],
   "source": [
    "#computing the number of parameters\n",
    "print(\"There are k*\", str(nb_songs+nb_users), '+', nb_params, \"parameters in this new model. \\nThe exact number depends on k.\")\n",
    "print(\"We still have\", nb_obs, \"observations to train this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14470"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_A_pivot = val_data_A.pivot_table(index=\"userID\", columns=\"songID\", values=\"rating\", dropna=False)\n",
    "val_data_A_pivot = pd.merge(pd.Series(train_data_pivot.index), val_data_A_pivot.reset_index(), how='outer', on='userID').set_index('userID')\n",
    "val_mat_A = val_data_A_pivot.values\n",
    "val_mat_A_mask = ~np.isnan(val_mat_A)\n",
    "np.sum(val_mat_A_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 - Validation MAE 0.2886936722736267\n",
      "iter 2 - Validation MAE 0.28647784501862783\n",
      "iter 3 - Validation MAE 0.28475858028767437\n",
      "iter 4 - Validation MAE 0.281602817007934\n",
      "iter 5 - Validation MAE 0.2819492455522867\n",
      "iter 6 - Validation MAE 0.2822331823592897\n",
      "iter 7 - Validation MAE 0.2822882939793443\n",
      "iter 8 - Validation MAE 0.28401391540358845\n",
      "iter 9 - Validation MAE 0.283926355676094\n",
      "iter 10 - Validation MAE 0.28592292185779267\n",
      "iter 11 - Validation MAE 0.28806453176663366\n",
      "iter 12 - Validation MAE 0.28647460705301986\n",
      "iter 13 - Validation MAE 0.2899378106903881\n",
      "iter 14 - Validation MAE 0.29170007448660057\n",
      "iter 15 - Validation MAE 0.29148619153565936\n",
      "iter 16 - Validation MAE 0.2920103456528623\n",
      "iter 17 - Validation MAE 0.2943806037227161\n",
      "iter 18 - Validation MAE 0.2954273917147392\n",
      "iter 19 - Validation MAE 0.29956652444751014\n",
      "iter 20 - Validation MAE 0.30130243615166097\n"
     ]
    }
   ],
   "source": [
    "cv_mae = []\n",
    "for i in range(20):\n",
    "    param_cv = i + 1\n",
    "    soft_imputer_cv = SoftImpute(max_rank=param_cv, verbose=False)\n",
    "    filled_centered_mat_cv = soft_imputer_cv.fit_transform(train_data_centered)\n",
    "    filled_mat_cv = biscaler.inverse_transform(filled_centered_mat_cv)\n",
    "    filled_mat_cv = np.clip(filled_mat_cv, 1, 5)\n",
    "    val_mae_cv = calculate_masked_mae(val_mat_A, filled_mat_cv, val_mat_A_mask)\n",
    "    cv_mae.append(val_mae_cv)\n",
    "    print('iter %s - Validation MAE %s' % (param_cv, val_mae_cv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,21), cv_mae)\n",
    "plt.xlabel('# users')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of k (number of users) that minimizes the MAE on the validation set A is 6.\n",
    "### iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 62.587108\n",
      "[SoftImpute] Iter 1: observed MAE=0.770978 rank=6\n",
      "[SoftImpute] Iter 2: observed MAE=0.757046 rank=6\n",
      "[SoftImpute] Iter 3: observed MAE=0.748145 rank=6\n",
      "[SoftImpute] Iter 4: observed MAE=0.742283 rank=6\n",
      "[SoftImpute] Iter 5: observed MAE=0.737416 rank=6\n",
      "[SoftImpute] Iter 6: observed MAE=0.733654 rank=6\n",
      "[SoftImpute] Iter 7: observed MAE=0.730600 rank=6\n",
      "[SoftImpute] Iter 8: observed MAE=0.728018 rank=6\n",
      "[SoftImpute] Iter 9: observed MAE=0.725793 rank=6\n",
      "[SoftImpute] Iter 10: observed MAE=0.723939 rank=6\n",
      "[SoftImpute] Iter 11: observed MAE=0.722218 rank=6\n",
      "[SoftImpute] Iter 12: observed MAE=0.720764 rank=6\n",
      "[SoftImpute] Iter 13: observed MAE=0.719451 rank=6\n",
      "[SoftImpute] Iter 14: observed MAE=0.718342 rank=6\n",
      "[SoftImpute] Iter 15: observed MAE=0.717273 rank=6\n",
      "[SoftImpute] Iter 16: observed MAE=0.716386 rank=6\n",
      "[SoftImpute] Iter 17: observed MAE=0.715568 rank=6\n",
      "[SoftImpute] Iter 18: observed MAE=0.714818 rank=6\n",
      "[SoftImpute] Iter 19: observed MAE=0.714176 rank=6\n",
      "[SoftImpute] Iter 20: observed MAE=0.713610 rank=6\n",
      "[SoftImpute] Iter 21: observed MAE=0.713075 rank=6\n",
      "[SoftImpute] Iter 22: observed MAE=0.712613 rank=6\n",
      "[SoftImpute] Iter 23: observed MAE=0.712180 rank=6\n",
      "[SoftImpute] Iter 24: observed MAE=0.711799 rank=6\n",
      "[SoftImpute] Iter 25: observed MAE=0.711436 rank=6\n",
      "[SoftImpute] Iter 26: observed MAE=0.711108 rank=6\n",
      "[SoftImpute] Iter 27: observed MAE=0.710831 rank=6\n",
      "[SoftImpute] Iter 28: observed MAE=0.710567 rank=6\n",
      "[SoftImpute] Iter 29: observed MAE=0.710309 rank=6\n",
      "[SoftImpute] Iter 30: observed MAE=0.710074 rank=6\n",
      "[SoftImpute] Iter 31: observed MAE=0.709854 rank=6\n",
      "[SoftImpute] Iter 32: observed MAE=0.709642 rank=6\n",
      "[SoftImpute] Iter 33: observed MAE=0.709473 rank=6\n",
      "[SoftImpute] Iter 34: observed MAE=0.709308 rank=6\n",
      "[SoftImpute] Iter 35: observed MAE=0.709157 rank=6\n",
      "[SoftImpute] Iter 36: observed MAE=0.709041 rank=6\n",
      "[SoftImpute] Iter 37: observed MAE=0.708890 rank=6\n",
      "[SoftImpute] Iter 38: observed MAE=0.708750 rank=6\n",
      "[SoftImpute] Iter 39: observed MAE=0.708615 rank=6\n",
      "[SoftImpute] Iter 40: observed MAE=0.708505 rank=6\n",
      "[SoftImpute] Iter 41: observed MAE=0.708387 rank=6\n",
      "[SoftImpute] Iter 42: observed MAE=0.708269 rank=6\n",
      "[SoftImpute] Iter 43: observed MAE=0.708153 rank=6\n",
      "[SoftImpute] Iter 44: observed MAE=0.708058 rank=6\n",
      "[SoftImpute] Iter 45: observed MAE=0.707955 rank=6\n",
      "[SoftImpute] Iter 46: observed MAE=0.707858 rank=6\n",
      "[SoftImpute] Iter 47: observed MAE=0.707770 rank=6\n",
      "[SoftImpute] Iter 48: observed MAE=0.707687 rank=6\n",
      "[SoftImpute] Iter 49: observed MAE=0.707607 rank=6\n",
      "[SoftImpute] Iter 50: observed MAE=0.707529 rank=6\n",
      "[SoftImpute] Iter 51: observed MAE=0.707446 rank=6\n",
      "[SoftImpute] Iter 52: observed MAE=0.707369 rank=6\n",
      "[SoftImpute] Iter 53: observed MAE=0.707295 rank=6\n",
      "[SoftImpute] Iter 54: observed MAE=0.707242 rank=6\n",
      "[SoftImpute] Iter 55: observed MAE=0.707187 rank=6\n",
      "[SoftImpute] Iter 56: observed MAE=0.707119 rank=6\n",
      "[SoftImpute] Iter 57: observed MAE=0.707059 rank=6\n",
      "[SoftImpute] Iter 58: observed MAE=0.706990 rank=6\n",
      "[SoftImpute] Iter 59: observed MAE=0.706929 rank=6\n",
      "[SoftImpute] Iter 60: observed MAE=0.706875 rank=6\n",
      "[SoftImpute] Iter 61: observed MAE=0.706818 rank=6\n",
      "[SoftImpute] Iter 62: observed MAE=0.706761 rank=6\n",
      "[SoftImpute] Iter 63: observed MAE=0.706718 rank=6\n",
      "[SoftImpute] Iter 64: observed MAE=0.706672 rank=6\n",
      "[SoftImpute] Iter 65: observed MAE=0.706635 rank=6\n",
      "[SoftImpute] Iter 66: observed MAE=0.706594 rank=6\n",
      "[SoftImpute] Iter 67: observed MAE=0.706551 rank=6\n",
      "[SoftImpute] Iter 68: observed MAE=0.706497 rank=6\n",
      "[SoftImpute] Iter 69: observed MAE=0.706472 rank=6\n",
      "[SoftImpute] Iter 70: observed MAE=0.706434 rank=6\n",
      "[SoftImpute] Iter 71: observed MAE=0.706398 rank=6\n",
      "[SoftImpute] Iter 72: observed MAE=0.706348 rank=6\n",
      "[SoftImpute] Iter 73: observed MAE=0.706308 rank=6\n",
      "[SoftImpute] Iter 74: observed MAE=0.706288 rank=6\n",
      "[SoftImpute] Iter 75: observed MAE=0.706256 rank=6\n",
      "[SoftImpute] Iter 76: observed MAE=0.706219 rank=6\n",
      "[SoftImpute] Iter 77: observed MAE=0.706186 rank=6\n",
      "[SoftImpute] Iter 78: observed MAE=0.706133 rank=6\n",
      "[SoftImpute] Iter 79: observed MAE=0.706081 rank=6\n",
      "[SoftImpute] Iter 80: observed MAE=0.706048 rank=6\n",
      "[SoftImpute] Iter 81: observed MAE=0.706004 rank=6\n",
      "[SoftImpute] Iter 82: observed MAE=0.705984 rank=6\n",
      "[SoftImpute] Iter 83: observed MAE=0.705949 rank=6\n",
      "[SoftImpute] Iter 84: observed MAE=0.705923 rank=6\n",
      "[SoftImpute] Iter 85: observed MAE=0.705908 rank=6\n",
      "[SoftImpute] Iter 86: observed MAE=0.705885 rank=6\n",
      "[SoftImpute] Iter 87: observed MAE=0.705851 rank=6\n",
      "[SoftImpute] Iter 88: observed MAE=0.705822 rank=6\n",
      "[SoftImpute] Iter 89: observed MAE=0.705808 rank=6\n",
      "[SoftImpute] Iter 90: observed MAE=0.705782 rank=6\n",
      "[SoftImpute] Iter 91: observed MAE=0.705769 rank=6\n",
      "[SoftImpute] Iter 92: observed MAE=0.705733 rank=6\n",
      "[SoftImpute] Iter 93: observed MAE=0.705693 rank=6\n",
      "[SoftImpute] Iter 94: observed MAE=0.705666 rank=6\n",
      "[SoftImpute] Iter 95: observed MAE=0.705640 rank=6\n",
      "[SoftImpute] Iter 96: observed MAE=0.705618 rank=6\n",
      "[SoftImpute] Iter 97: observed MAE=0.705587 rank=6\n",
      "[SoftImpute] Iter 98: observed MAE=0.705571 rank=6\n",
      "[SoftImpute] Iter 99: observed MAE=0.705558 rank=6\n",
      "[SoftImpute] Iter 100: observed MAE=0.705534 rank=6\n",
      "[SoftImpute] Stopped after iteration 100 for lambda=1.251742\n"
     ]
    }
   ],
   "source": [
    "#building the final model witht the right value of k\n",
    "soft_imputer = SoftImpute(max_rank=6, verbose=True)\n",
    "soft_imputer_filled = soft_imputer.fit_transform(train_data_centered)\n",
    "test_soft_imputer_filled = biscaler.inverse_transform(soft_imputer_filled)\n",
    "test_soft_imputer_filled = np.clip(test_soft_imputer_filled, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SoftImpute MAE is:  0.28281460544961295\n",
      "The SoftImpute RMSE is:  0.38656501371828306\n",
      "The SoftImpute normalized MAE is:  0.07070365136240324\n",
      "The SoftImpute normalized RMSE is:  0.09664125342957076\n",
      "The SoftImpute R2 is:  0.31035996288799916\n"
     ]
    }
   ],
   "source": [
    "mae_softimpute = calculate_masked_mae(test_matrix, test_soft_imputer_filled, test_matrix_mask)\n",
    "print(\"The SoftImpute MAE is: \", mae_softimpute)\n",
    "\n",
    "mse_softimpute = calculate_masked_mse(test_matrix, test_soft_imputer_filled, test_matrix_mask)\n",
    "print(\"The SoftImpute RMSE is: \", np.sqrt(mse_softimpute))\n",
    "\n",
    "normalized_mae_softimpute = mae_softimpute/4\n",
    "print(\"The SoftImpute normalized MAE is: \", normalized_mae_softimpute)\n",
    "\n",
    "normalized_rmse_softimpute = np.sqrt(mse_softimpute)/4\n",
    "print(\"The SoftImpute normalized RMSE is: \", normalized_rmse_softimpute)\n",
    "\n",
    "baseline_prediction = np.mean(train_data.rating)\n",
    "baseline_model = baseline_prediction*np.ones((nb_users, nb_songs))\n",
    "baseline_mse = calculate_masked_mse(test_matrix, baseline_model, test_matrix_mask)\n",
    "print(\"The SoftImpute R2 is: \", calculate_OSR2(model_mse=mse_softimpute, baseline_mse=baseline_mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the independent features\n",
    "unique_genre = list(train_data['genre'].unique())\n",
    "unique_year = list(train_data['year'].unique())\n",
    "unique_year.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the train and test datasets to perform the task on \n",
    "\n",
    "train_X = pd.DataFrame()\n",
    "test_X = pd.DataFrame()\n",
    "\n",
    "for g in range(len(unique_genre)-1):\n",
    "    train_X['genre'+str(g+1)] = train_data['genre'].apply(lambda x : 1 if x == unique_genre[g] else 0)\n",
    "    test_X['genre'+str(g+1)] = test_data['genre'].apply(lambda x : 1 if x == unique_genre[g] else 0)\n",
    "\n",
    "for y in range(len(unique_year)-1):\n",
    "    train_X['year'+str(y+1)] = train_data['year'].apply(lambda x : 1 if x == unique_year[y] else 0)\n",
    "    test_X['year'+str(y+1)] = test_data['year'].apply(lambda x : 1 if x == unique_year[y] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre1</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "      <th>genre4</th>\n",
       "      <th>genre5</th>\n",
       "      <th>genre6</th>\n",
       "      <th>year1</th>\n",
       "      <th>year2</th>\n",
       "      <th>year3</th>\n",
       "      <th>year4</th>\n",
       "      <th>...</th>\n",
       "      <th>year18</th>\n",
       "      <th>year19</th>\n",
       "      <th>year20</th>\n",
       "      <th>year21</th>\n",
       "      <th>year22</th>\n",
       "      <th>year23</th>\n",
       "      <th>year24</th>\n",
       "      <th>year25</th>\n",
       "      <th>year26</th>\n",
       "      <th>year27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245992</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245993</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245994</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245997 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        genre1  genre2  genre3  genre4  genre5  genre6  year1  year2  year3  \\\n",
       "0            1       0       0       0       0       0      0      0      0   \n",
       "1            0       1       0       0       0       0      0      0      0   \n",
       "2            1       0       0       0       0       0      0      0      0   \n",
       "3            0       0       1       0       0       0      0      0      0   \n",
       "4            1       0       0       0       0       0      0      0      0   \n",
       "...        ...     ...     ...     ...     ...     ...    ...    ...    ...   \n",
       "245992       1       0       0       0       0       0      0      0      0   \n",
       "245993       0       1       0       0       0       0      0      0      0   \n",
       "245994       1       0       0       0       0       0      0      0      0   \n",
       "245995       1       0       0       0       0       0      0      0      0   \n",
       "245996       0       0       0       1       0       0      0      0      0   \n",
       "\n",
       "        year4  ...  year18  year19  year20  year21  year22  year23  year24  \\\n",
       "0           0  ...       0       0       0       1       0       0       0   \n",
       "1           0  ...       0       0       0       0       0       0       0   \n",
       "2           0  ...       0       0       0       0       0       0       0   \n",
       "3           0  ...       0       0       0       1       0       0       0   \n",
       "4           0  ...       0       0       0       0       0       0       1   \n",
       "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "245992      0  ...       0       1       0       0       0       0       0   \n",
       "245993      0  ...       0       0       0       0       0       0       0   \n",
       "245994      0  ...       0       0       0       0       0       0       0   \n",
       "245995      0  ...       0       0       0       0       0       0       0   \n",
       "245996      0  ...       0       0       0       0       0       0       0   \n",
       "\n",
       "        year25  year26  year27  \n",
       "0            0       0       0  \n",
       "1            0       0       1  \n",
       "2            1       0       0  \n",
       "3            0       0       0  \n",
       "4            0       0       0  \n",
       "...        ...     ...     ...  \n",
       "245992       0       0       0  \n",
       "245993       1       0       0  \n",
       "245994       1       0       0  \n",
       "245995       0       0       0  \n",
       "245996       0       1       0  \n",
       "\n",
       "[245997 rows x 33 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the target\n",
    "\n",
    "train_y = train_data['rating']\n",
    "test_y = test_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the models \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing Grid Search to find the optimal ccp alpha\n",
    "\n",
    "param_grid = {'ccp_alpha': np.linspace(0, 0.01, 75)}\n",
    "tree_reg = DecisionTreeRegressor(random_state=2)\n",
    "grid_search = GridSearchCV(tree_reg, param_grid=param_grid, cv=10).fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), (75,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha = grid_search.best_params_['ccp_alpha']\n",
    "mean_scores = grid_search.cv_results_['mean_test_score']\n",
    "best_alpha.shape, mean_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict with model 1\n",
    "model1 = DecisionTreeRegressor(random_state=42)\n",
    "model1.fit(train_X, train_y)\n",
    "y_pred_1 = model1.predict(test_X)\n",
    "test_mae1 = mean_absolute_error(test_y, y_pred_1)\n",
    "test_rmse1 = mean_squared_error(test_y, y_pred_1, squared=False)\n",
    "test_r2_1 = r2_score(test_y, y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict with model 2\n",
    "model2 = LinearRegression()\n",
    "model2.fit(train_X, train_y)\n",
    "y_pred_2 = model2.predict(test_X)\n",
    "test_mae2 = mean_absolute_error(test_y, y_pred_2)\n",
    "test_rmse2 = mean_squared_error(test_y, y_pred_2, squared=False)\n",
    "test_r2_2 = r2_score(test_y, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model      MAE     RMSE  Normalized MAE  Normalized RMSE     OSR2\n",
      "Model 1 0.368092 0.455405        0.092023         0.113851 0.042862\n",
      "Model 2 0.371157 0.458016        0.092789         0.114504 0.031852\n"
     ]
    }
   ],
   "source": [
    "# Create a table with the results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Model 1', 'Model 2'],\n",
    "    'MAE': [test_mae1, test_mae2],\n",
    "    'RMSE': [test_rmse1, test_rmse2],\n",
    "    'Normalized MAE': [test_mae1/4, test_mae2/4],\n",
    "    'Normalized RMSE': [test_rmse1/4, test_rmse2/4],\n",
    "    'OSR2': [test_r2_1, test_r2_2]\n",
    "})\n",
    "\n",
    "# Print the table\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) ii) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframes \n",
    "\n",
    "val_B_X = pd.DataFrame()\n",
    "for g in range(len(unique_genre)-1):\n",
    "    val_B_X['genre'+str(g+1)] = val_data_B['genre'].apply(lambda x : 1 if x == unique_genre[g] else 0)\n",
    "\n",
    "for y in range(len(unique_year)-1):\n",
    "    val_B_X['year'+str(y+1)] = val_data_B['year'].apply(lambda x : 1 if x == unique_year[y] else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the trained models \n",
    "\n",
    "pred_B_1_y = model1.predict(val_B_X)\n",
    "pred_B_2_y = model2.predict(val_B_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 62.587030\n",
      "[SoftImpute] Iter 1: observed MAE=0.770594 rank=6\n",
      "[SoftImpute] Iter 2: observed MAE=0.756299 rank=6\n",
      "[SoftImpute] Iter 3: observed MAE=0.748058 rank=6\n",
      "[SoftImpute] Iter 4: observed MAE=0.741980 rank=6\n",
      "[SoftImpute] Iter 5: observed MAE=0.737155 rank=6\n",
      "[SoftImpute] Iter 6: observed MAE=0.733282 rank=6\n",
      "[SoftImpute] Iter 7: observed MAE=0.730110 rank=6\n",
      "[SoftImpute] Iter 8: observed MAE=0.727480 rank=6\n",
      "[SoftImpute] Iter 9: observed MAE=0.725215 rank=6\n",
      "[SoftImpute] Iter 10: observed MAE=0.723249 rank=6\n",
      "[SoftImpute] Iter 11: observed MAE=0.721563 rank=6\n",
      "[SoftImpute] Iter 12: observed MAE=0.720066 rank=6\n",
      "[SoftImpute] Iter 13: observed MAE=0.718758 rank=6\n",
      "[SoftImpute] Iter 14: observed MAE=0.717550 rank=6\n",
      "[SoftImpute] Iter 15: observed MAE=0.716548 rank=6\n",
      "[SoftImpute] Iter 16: observed MAE=0.715662 rank=6\n",
      "[SoftImpute] Iter 17: observed MAE=0.714871 rank=6\n",
      "[SoftImpute] Iter 18: observed MAE=0.714153 rank=6\n",
      "[SoftImpute] Iter 19: observed MAE=0.713538 rank=6\n",
      "[SoftImpute] Iter 20: observed MAE=0.712973 rank=6\n",
      "[SoftImpute] Iter 21: observed MAE=0.712485 rank=6\n",
      "[SoftImpute] Iter 22: observed MAE=0.712024 rank=6\n",
      "[SoftImpute] Iter 23: observed MAE=0.711618 rank=6\n",
      "[SoftImpute] Iter 24: observed MAE=0.711263 rank=6\n",
      "[SoftImpute] Iter 25: observed MAE=0.710910 rank=6\n",
      "[SoftImpute] Iter 26: observed MAE=0.710596 rank=6\n",
      "[SoftImpute] Iter 27: observed MAE=0.710298 rank=6\n",
      "[SoftImpute] Iter 28: observed MAE=0.710036 rank=6\n",
      "[SoftImpute] Iter 29: observed MAE=0.709813 rank=6\n",
      "[SoftImpute] Iter 30: observed MAE=0.709589 rank=6\n",
      "[SoftImpute] Iter 31: observed MAE=0.709386 rank=6\n",
      "[SoftImpute] Iter 32: observed MAE=0.709183 rank=6\n",
      "[SoftImpute] Iter 33: observed MAE=0.709007 rank=6\n",
      "[SoftImpute] Iter 34: observed MAE=0.708841 rank=6\n",
      "[SoftImpute] Iter 35: observed MAE=0.708697 rank=6\n",
      "[SoftImpute] Iter 36: observed MAE=0.708549 rank=6\n",
      "[SoftImpute] Iter 37: observed MAE=0.708407 rank=6\n",
      "[SoftImpute] Iter 38: observed MAE=0.708285 rank=6\n",
      "[SoftImpute] Iter 39: observed MAE=0.708163 rank=6\n",
      "[SoftImpute] Iter 40: observed MAE=0.708043 rank=6\n",
      "[SoftImpute] Iter 41: observed MAE=0.707930 rank=6\n",
      "[SoftImpute] Iter 42: observed MAE=0.707840 rank=6\n",
      "[SoftImpute] Iter 43: observed MAE=0.707742 rank=6\n",
      "[SoftImpute] Iter 44: observed MAE=0.707644 rank=6\n",
      "[SoftImpute] Iter 45: observed MAE=0.707559 rank=6\n",
      "[SoftImpute] Iter 46: observed MAE=0.707481 rank=6\n",
      "[SoftImpute] Iter 47: observed MAE=0.707396 rank=6\n",
      "[SoftImpute] Iter 48: observed MAE=0.707330 rank=6\n",
      "[SoftImpute] Iter 49: observed MAE=0.707252 rank=6\n",
      "[SoftImpute] Iter 50: observed MAE=0.707175 rank=6\n",
      "[SoftImpute] Iter 51: observed MAE=0.707101 rank=6\n",
      "[SoftImpute] Iter 52: observed MAE=0.707030 rank=6\n",
      "[SoftImpute] Iter 53: observed MAE=0.706972 rank=6\n",
      "[SoftImpute] Iter 54: observed MAE=0.706934 rank=6\n",
      "[SoftImpute] Iter 55: observed MAE=0.706862 rank=6\n",
      "[SoftImpute] Iter 56: observed MAE=0.706803 rank=6\n",
      "[SoftImpute] Iter 57: observed MAE=0.706763 rank=6\n",
      "[SoftImpute] Iter 58: observed MAE=0.706711 rank=6\n",
      "[SoftImpute] Iter 59: observed MAE=0.706662 rank=6\n",
      "[SoftImpute] Iter 60: observed MAE=0.706612 rank=6\n",
      "[SoftImpute] Iter 61: observed MAE=0.706573 rank=6\n",
      "[SoftImpute] Iter 62: observed MAE=0.706532 rank=6\n",
      "[SoftImpute] Iter 63: observed MAE=0.706491 rank=6\n",
      "[SoftImpute] Iter 64: observed MAE=0.706452 rank=6\n",
      "[SoftImpute] Iter 65: observed MAE=0.706417 rank=6\n",
      "[SoftImpute] Iter 66: observed MAE=0.706370 rank=6\n",
      "[SoftImpute] Iter 67: observed MAE=0.706333 rank=6\n",
      "[SoftImpute] Iter 68: observed MAE=0.706299 rank=6\n",
      "[SoftImpute] Iter 69: observed MAE=0.706261 rank=6\n",
      "[SoftImpute] Iter 70: observed MAE=0.706222 rank=6\n",
      "[SoftImpute] Iter 71: observed MAE=0.706179 rank=6\n",
      "[SoftImpute] Iter 72: observed MAE=0.706142 rank=6\n",
      "[SoftImpute] Iter 73: observed MAE=0.706109 rank=6\n",
      "[SoftImpute] Iter 74: observed MAE=0.706074 rank=6\n",
      "[SoftImpute] Iter 75: observed MAE=0.706042 rank=6\n",
      "[SoftImpute] Iter 76: observed MAE=0.706021 rank=6\n",
      "[SoftImpute] Iter 77: observed MAE=0.705974 rank=6\n",
      "[SoftImpute] Iter 78: observed MAE=0.705953 rank=6\n",
      "[SoftImpute] Iter 79: observed MAE=0.705934 rank=6\n",
      "[SoftImpute] Iter 80: observed MAE=0.705901 rank=6\n",
      "[SoftImpute] Iter 81: observed MAE=0.705881 rank=6\n",
      "[SoftImpute] Iter 82: observed MAE=0.705846 rank=6\n",
      "[SoftImpute] Iter 83: observed MAE=0.705820 rank=6\n",
      "[SoftImpute] Iter 84: observed MAE=0.705799 rank=6\n",
      "[SoftImpute] Iter 85: observed MAE=0.705762 rank=6\n",
      "[SoftImpute] Iter 86: observed MAE=0.705747 rank=6\n",
      "[SoftImpute] Iter 87: observed MAE=0.705699 rank=6\n",
      "[SoftImpute] Iter 88: observed MAE=0.705673 rank=6\n",
      "[SoftImpute] Iter 89: observed MAE=0.705636 rank=6\n",
      "[SoftImpute] Iter 90: observed MAE=0.705626 rank=6\n",
      "[SoftImpute] Iter 91: observed MAE=0.705606 rank=6\n",
      "[SoftImpute] Iter 92: observed MAE=0.705585 rank=6\n",
      "[SoftImpute] Iter 93: observed MAE=0.705575 rank=6\n",
      "[SoftImpute] Iter 94: observed MAE=0.705553 rank=6\n",
      "[SoftImpute] Iter 95: observed MAE=0.705527 rank=6\n",
      "[SoftImpute] Iter 96: observed MAE=0.705510 rank=6\n",
      "[SoftImpute] Iter 97: observed MAE=0.705510 rank=6\n",
      "[SoftImpute] Iter 98: observed MAE=0.705481 rank=6\n",
      "[SoftImpute] Iter 99: observed MAE=0.705452 rank=6\n",
      "[SoftImpute] Iter 100: observed MAE=0.705433 rank=6\n",
      "[SoftImpute] Stopped after iteration 100 for lambda=1.251741\n"
     ]
    }
   ],
   "source": [
    "#fitting the Soft Imputer\n",
    "\n",
    "val_B_pivot = val_data_B.pivot_table(index=\"userID\", columns = \"songID\", values = \"rating\", dropna=False)\n",
    "val_B_pivot = pd.merge(pd.Series(train_data_pivot.index),val_B_pivot.reset_index(),how='outer',on='userID').set_index('userID')\n",
    "matrix_val_B = val_B_pivot.to_numpy()\n",
    "matrix_val_B_mask =  ~np.isnan(matrix_val_B)\n",
    "\n",
    "\n",
    "mat_B_centered_filled = soft_imputer.fit_transform(train_data_centered)\n",
    "val_B_soft_imputer_filled = biscaler.inverse_transform(mat_B_centered_filled)\n",
    "val_B_soft_imputer_filled = np.clip(test_soft_imputer_filled, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the predicted ratings for val B dataset\n",
    "\n",
    "y_coll_filter_B = []\n",
    "\n",
    "for i in range(len(val_data_B)):\n",
    "    user , song = val_data_B['userID'].iloc[i]-1 , val_data_B['songID'].iloc[i]-1\n",
    "    y_coll_filter_B.append(val_B_soft_imputer_filled[user,song])\n",
    "\n",
    "y_coll_filter_B = pd.Series(y_coll_filter_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the predictor and target variables\n",
    "X = pd.DataFrame({\n",
    "    'Regression Tree': pred_B_1_y,\n",
    "    'Linear Regression': pred_B_2_y,\n",
    "    'Collaborative Filtering': y_coll_filter_B\n",
    "})\n",
    "y = val_data_B['rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the OLS regression model\n",
    "model = sm.OLS(y, X).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 rating   R-squared (uncentered):                   0.926\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.926\n",
      "Method:                 Least Squares   F-statistic:                          6.014e+04\n",
      "Date:                Sun, 23 Apr 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        21:35:02   Log-Likelihood:                         -6559.3\n",
      "No. Observations:               14471   AIC:                                  1.312e+04\n",
      "Df Residuals:                   14468   BIC:                                  1.315e+04\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Regression Tree             0.1797      0.062      2.887      0.004       0.058       0.302\n",
      "Linear Regression           0.0111      0.061      0.182      0.856      -0.109       0.131\n",
      "Collaborative Filtering     0.8013      0.011     74.286      0.000       0.780       0.822\n",
      "==============================================================================\n",
      "Omnibus:                     3034.196   Durbin-Watson:                   2.015\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9202.653\n",
      "Skew:                           1.084   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.251   Cond. No.                         63.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediciting outcomes for both models for coll filtering\n",
    "\n",
    "y_test_1 = model1.predict(test_X)\n",
    "y_test_2 = model2.predict(test_X)\n",
    "y_coll_filter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining collaborative filtering series\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    user , song = test_data['userID'].iloc[i]-1 , test_data['songID'].iloc[i]-1\n",
    "    y_coll_filter.append(test_soft_imputer_filled[user,song])\n",
    "\n",
    "y_coll_filter = pd.Series(y_coll_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicitng results for blended model\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    {'Regression Tree': y_test_1, \n",
    "    'Linear Regression': y_test_2, \n",
    "    'Collaborative Filtering': y_coll_filter})\n",
    "\n",
    "y_test = test_data['rating']\n",
    "y_blended = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining metrics for each model\n",
    "\n",
    "models =  ['Regression Tree','Linear Regression','Collaborative Filtering','Blended']\n",
    "metrics = ['Normalized RMSE','Normalized MAE','OSR2']\n",
    "\n",
    "RMSE = [test_rmse1/4, test_rmse2/4, mean_squared_error(y_test, y_coll_filter, squared=False)/4, mean_squared_error(y_test, y_blended, squared=False)/4]\n",
    "MAE = [test_mae1/4, test_mae2/4,mean_absolute_error(y_test, y_coll_filter)/4, mean_absolute_error(y_test, y_blended)/4]\n",
    "OSR2 = [test_r2_1, test_r2_2, r2_score(y_test, y_coll_filter), r2_score(y_test, y_blended)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized RMSE</th>\n",
       "      <th>Normalized MAE</th>\n",
       "      <th>OSR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Regression Tree</th>\n",
       "      <td>0.113851</td>\n",
       "      <td>0.092023</td>\n",
       "      <td>0.042862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.114504</td>\n",
       "      <td>0.092789</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Collaborative Filtering</th>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.070704</td>\n",
       "      <td>0.310356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blended</th>\n",
       "      <td>0.095779</td>\n",
       "      <td>0.072535</td>\n",
       "      <td>0.322614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Normalized RMSE  Normalized MAE      OSR2\n",
       "Regression Tree                 0.113851        0.092023  0.042862\n",
       "Linear Regression               0.114504        0.092789  0.031852\n",
       "Collaborative Filtering         0.096641        0.070704  0.310356\n",
       "Blended                         0.095779        0.072535  0.322614"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the results \n",
    "\n",
    "table = pd.DataFrame(columns = metrics ,data={'Normalized RMSE' :RMSE,'Normalized MAE' :MAE , 'OSR2' :OSR2},index=models)\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a05f4eab8a48e0fb699a9c4d2ff5136ad6fe08181e3a510e3ac6da38970e2134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
