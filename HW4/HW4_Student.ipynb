{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl0OH3XGTXe1"
   },
   "source": [
    "# HW5 Skeleton Code\n",
    "Please note that this skeleton code is provided to help you with homework.\n",
    "Full description of each question can be found on HW5.pdf, so please read instruction of each question carefully. There might be some questions that is not presented in this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1QYqL7lvuvmK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awc_PHjUuvmR"
   },
   "source": [
    "## Q. Changing HTML Text to Plain Text\n",
    "\n",
    "The Python library <b>BeautifulSoup</b> is useful for dealing with html text. In order to use this library, you will need to install it first by running the following command: \n",
    " <b>conda install beautifulsoup4</b> \n",
    " in the terminal.\n",
    " <br> In the code, you can import it by running the following line: \n",
    "<br> \n",
    "  <b>from bs4 import BeautifulSoup </b>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary remark\n",
    "\n",
    "My first remark is that when I split the train and test sets from the start, my vectorization will cause me problems. Indeed, the features will not be the same for the train dataset and the test one. I will not be able to use the trained model for prediction on the test set. Thus, I will concatenate both dataframes and only split them at the very end, to make sure all the featured words are contained in both training and test sets eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JaHFZFOuuvmU"
   },
   "outputs": [],
   "source": [
    "  #Read our data file\n",
    "\n",
    "df_train = pd.read_csv('stack_stats_2023_train.csv') #Todo\n",
    "df_test = pd.read_csv('stack_stats_2023_test.csv') #Todo\n",
    "\n",
    "#as explained before, I will concatenate the datasets\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jzyC4JZpuvmW"
   },
   "outputs": [],
   "source": [
    "#Cleaning 'Body'\n",
    "#Change HTML Text to Plain text using get_text() function from BeautifulSoup\n",
    "#If you are not familiar with the apply method, please check discussion week 10 lecture and code.\n",
    "\n",
    "df['Body'] = df['Body'].apply(lambda  x: BeautifulSoup(x, 'html.parser').get_text() ) #Todo\n",
    "#Manually cleaned up newline tag \\n and tab tag \\t.\n",
    "df['Body'] = df['Body'].apply(lambda  x: x.replace('\\n', '')) #Todo\n",
    "df['Body'] = df['Body'].apply(lambda x: x.replace('\\t', '')) #Todo\n",
    "#If you need any other cleaning process, please uncomment the below.\n",
    "#df_train['Body'] = df_train['Body'].apply(lambda ) #Todo\n",
    "\n",
    "#Cleaning Tags\n",
    "#This would be somewhat similar to the above.\n",
    "\n",
    "#Todo: Clean Tags, please feel free to add any lines below\n",
    "df['Tags'] = df['Tags'].apply(lambda  x: x.replace('<', '').replace('>', ' ')) \n",
    "\n",
    "\n",
    "#Todo: Repeat the same process for test dataset \n",
    "# => no need to do this in my situation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502641</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm a master's student in EECS working my way ...</td>\n",
       "      <td>Why does the PyTorch tutorial on DQN define st...</td>\n",
       "      <td>machine-learning reinforcement-learning q-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477291</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not know if this is a good question, but ...</td>\n",
       "      <td>Does random walking have a memory?</td>\n",
       "      <td>probability law-of-large-numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448489</td>\n",
       "      <td>4</td>\n",
       "      <td>I am doing 10 times repeated 10-fold cross-val...</td>\n",
       "      <td>Which statistic to report for repeated cross-v...</td>\n",
       "      <td>cross-validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487075</td>\n",
       "      <td>0</td>\n",
       "      <td>I have a dataset with 1MM records, around 40 f...</td>\n",
       "      <td>Binary classification on imbalanced data - odd...</td>\n",
       "      <td>unbalanced-classes calibration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481670</td>\n",
       "      <td>2</td>\n",
       "      <td>I want to run a regression where one of the ex...</td>\n",
       "      <td>How to best summarize Likert data (to use as a...</td>\n",
       "      <td>multiple-regression missing-data likert item-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  502641      1  I'm a master's student in EECS working my way ...   \n",
       "1  477291      1  I do not know if this is a good question, but ...   \n",
       "2  448489      4  I am doing 10 times repeated 10-fold cross-val...   \n",
       "3  487075      0  I have a dataset with 1MM records, around 40 f...   \n",
       "4  481670      2  I want to run a regression where one of the ex...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Why does the PyTorch tutorial on DQN define st...   \n",
       "1                 Does random walking have a memory?   \n",
       "2  Which statistic to report for repeated cross-v...   \n",
       "3  Binary classification on imbalanced data - odd...   \n",
       "4  How to best summarize Likert data (to use as a...   \n",
       "\n",
       "                                                Tags  \n",
       "0  machine-learning reinforcement-learning q-lear...  \n",
       "1                  probability law-of-large-numbers   \n",
       "2                                  cross-validation   \n",
       "3                    unbalanced-classes calibration   \n",
       "4  multiple-regression missing-data likert item-r...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNS-3DkCuvmb"
   },
   "source": [
    "## Q. Basic Text Cleaning and Merging into a single Text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "031sBi5Duvmc"
   },
   "source": [
    "### Change to Lower Case, Remove puncuation, digits, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "t-YUYKlvuvmd"
   },
   "outputs": [],
   "source": [
    "#Change to Lowercase\n",
    "\n",
    "df[['Body','Title','Tags']] = df[['Body','Title','Tags']].applymap(str.lower) #Todo, do you see why we used applymap instead of apply in this case? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cas, we used applymap because we are mapping the function we want to use, here it is 'apply', accross different tags or categories of data and we want the function to be applied dependently on each of those categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Bbcp_w_wuvme"
   },
   "outputs": [],
   "source": [
    "#Remove Punctations \n",
    "from string import punctuation\n",
    "\n",
    "#You can get this function from our discussion session code. However, we leave it as a blank for a practice.\n",
    "def remove_punctuation(document):\n",
    "\n",
    "    no_punct = ''.join([character for character in document if character not in punctuation])\n",
    "    \n",
    "    return no_punct\n",
    "\n",
    "df[['Body','Title','Tags']] = df[['Body','Title','Tags']].applymap(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yNUiymSJuvmh"
   },
   "outputs": [],
   "source": [
    "#Remove Digits \n",
    "\n",
    "def remove_digit(document): \n",
    "    \n",
    "    no_digit = ''.join([character for character in document if not character.isdigit()])\n",
    "              \n",
    "    return no_digit\n",
    "\n",
    "df[['Body','Title','Tags']] = df[['Body','Title','Tags']].applymap(remove_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502641</td>\n",
       "      <td>1</td>\n",
       "      <td>im a masters student in eecs working my way to...</td>\n",
       "      <td>why does the pytorch tutorial on dqn define st...</td>\n",
       "      <td>machinelearning reinforcementlearning qlearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477291</td>\n",
       "      <td>1</td>\n",
       "      <td>i do not know if this is a good question but i...</td>\n",
       "      <td>does random walking have a memory</td>\n",
       "      <td>probability lawoflargenumbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448489</td>\n",
       "      <td>4</td>\n",
       "      <td>i am doing  times repeated fold crossvalidatio...</td>\n",
       "      <td>which statistic to report for repeated crossva...</td>\n",
       "      <td>crossvalidation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487075</td>\n",
       "      <td>0</td>\n",
       "      <td>i have a dataset with mm records around  featu...</td>\n",
       "      <td>binary classification on imbalanced data  odd ...</td>\n",
       "      <td>unbalancedclasses calibration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481670</td>\n",
       "      <td>2</td>\n",
       "      <td>i want to run a regression where one of the ex...</td>\n",
       "      <td>how to best summarize likert data to use as an...</td>\n",
       "      <td>multipleregression missingdata likert itemresp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  502641      1  im a masters student in eecs working my way to...   \n",
       "1  477291      1  i do not know if this is a good question but i...   \n",
       "2  448489      4  i am doing  times repeated fold crossvalidatio...   \n",
       "3  487075      0  i have a dataset with mm records around  featu...   \n",
       "4  481670      2  i want to run a regression where one of the ex...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  why does the pytorch tutorial on dqn define st...   \n",
       "1                  does random walking have a memory   \n",
       "2  which statistic to report for repeated crossva...   \n",
       "3  binary classification on imbalanced data  odd ...   \n",
       "4  how to best summarize likert data to use as an...   \n",
       "\n",
       "                                                Tags  \n",
       "0   machinelearning reinforcementlearning qlearning   \n",
       "1                     probability lawoflargenumbers   \n",
       "2                                   crossvalidation   \n",
       "3                     unbalancedclasses calibration   \n",
       "4  multipleregression missingdata likert itemresp...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAsCQQPQuvmi"
   },
   "source": [
    "### Tokenization and Remove Stopwords and do stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25821,
     "status": "ok",
     "timestamp": 1668123057199,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "gOrVZxXQuvmj",
    "outputId": "07dd90e0-e5ca-4634-f43f-f379fe3a0787"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "df[['Body','Title','Tags']] = df[['Body','Title','Tags']].applymap(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2684,
     "status": "ok",
     "timestamp": 1668123197885,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "82DJNdV1uvmj",
    "outputId": "8f8148ae-7551-43fc-d3d3-2bc8d8202d15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "#Remove Stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(document):\n",
    "    \n",
    "    words = [word for word in document if not word in stop_words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "df[['Body','Title','Tags']] = df[['Body','Title','Tags']].applymap(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "54S-irnRuvmk"
   },
   "outputs": [],
   "source": [
    "#We use porter stemming \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stemmer(document):\n",
    "    \n",
    "    stemmed_document = [porter.stem(word) for word in document]\n",
    "    \n",
    "    return stemmed_document\n",
    "\n",
    "df[['Body','Title','Tags']] = df[['Body','Title','Tags']].applymap(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2sfBcaMLTok"
   },
   "source": [
    "## Let's Check our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "r6V33S7pLS76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502641</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, master, student, eec, work, way, toward, ...</td>\n",
       "      <td>[pytorch, tutori, dqn, defin, state, differ]</td>\n",
       "      <td>[machinelearn, reinforcementlearn, qlearn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477291</td>\n",
       "      <td>1</td>\n",
       "      <td>[know, good, question, found, answer, anywher,...</td>\n",
       "      <td>[random, walk, memori]</td>\n",
       "      <td>[probabl, lawoflargenumb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448489</td>\n",
       "      <td>4</td>\n",
       "      <td>[time, repeat, fold, crossvalid, want, report,...</td>\n",
       "      <td>[statist, report, repeat, crossvalid]</td>\n",
       "      <td>[crossvalid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487075</td>\n",
       "      <td>0</td>\n",
       "      <td>[dataset, mm, record, around, featur, class, i...</td>\n",
       "      <td>[binari, classif, imbalanc, data, odd, calibr,...</td>\n",
       "      <td>[unbalancedclass, calibr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481670</td>\n",
       "      <td>2</td>\n",
       "      <td>[want, run, regress, one, explanatori, variabl...</td>\n",
       "      <td>[best, summar, likert, data, use, independ, va...</td>\n",
       "      <td>[multipleregress, missingdata, likert, itemres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  502641      1  [im, master, student, eec, work, way, toward, ...   \n",
       "1  477291      1  [know, good, question, found, answer, anywher,...   \n",
       "2  448489      4  [time, repeat, fold, crossvalid, want, report,...   \n",
       "3  487075      0  [dataset, mm, record, around, featur, class, i...   \n",
       "4  481670      2  [want, run, regress, one, explanatori, variabl...   \n",
       "\n",
       "                                               Title  \\\n",
       "0       [pytorch, tutori, dqn, defin, state, differ]   \n",
       "1                             [random, walk, memori]   \n",
       "2              [statist, report, repeat, crossvalid]   \n",
       "3  [binari, classif, imbalanc, data, odd, calibr,...   \n",
       "4  [best, summar, likert, data, use, independ, va...   \n",
       "\n",
       "                                                Tags  \n",
       "0         [machinelearn, reinforcementlearn, qlearn]  \n",
       "1                          [probabl, lawoflargenumb]  \n",
       "2                                       [crossvalid]  \n",
       "3                          [unbalancedclass, calibr]  \n",
       "4  [multipleregress, missingdata, likert, itemres...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFgV2VL0uvml"
   },
   "source": [
    "### Q. Treat Three text data independently and merge into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VCB-voc_uvmm"
   },
   "outputs": [],
   "source": [
    "#Treat Three types of data independently\n",
    "#let's define functions that will help this operation\n",
    "\n",
    "def add_body(document):\n",
    "    \n",
    "    added_document = [x + str('_body') for x in document]\n",
    "    \n",
    "    return added_document\n",
    "\n",
    "def add_title(document):\n",
    "    \n",
    "    added_document = [x + str('_title') for x in document]\n",
    "    \n",
    "    return added_document\n",
    "\n",
    "def add_tags(document):\n",
    "    \n",
    "    added_document = [x + str('_tags') for x in document]\n",
    "    \n",
    "    return added_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UWy0BGVHuvmm"
   },
   "outputs": [],
   "source": [
    "df['Body'] = df['Body'].apply(add_body)\n",
    "df['Title'] = df['Title'].apply(add_title)\n",
    "df['Tags'] = df['Tags'].apply(add_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kgcE1Vcnuvmn"
   },
   "outputs": [],
   "source": [
    "#Now we need to merge all those 3 columns into a single column. Implement this below.\n",
    "df['text'] = df['Body'] + df['Title'] + df['Tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq2PYhnmLhDi"
   },
   "source": [
    "## Let's check our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rtYP_Lu3LjIb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502641</td>\n",
       "      <td>1</td>\n",
       "      <td>[im_body, master_body, student_body, eec_body,...</td>\n",
       "      <td>[pytorch_title, tutori_title, dqn_title, defin...</td>\n",
       "      <td>[machinelearn_tags, reinforcementlearn_tags, q...</td>\n",
       "      <td>[im_body, master_body, student_body, eec_body,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477291</td>\n",
       "      <td>1</td>\n",
       "      <td>[know_body, good_body, question_body, found_bo...</td>\n",
       "      <td>[random_title, walk_title, memori_title]</td>\n",
       "      <td>[probabl_tags, lawoflargenumb_tags]</td>\n",
       "      <td>[know_body, good_body, question_body, found_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448489</td>\n",
       "      <td>4</td>\n",
       "      <td>[time_body, repeat_body, fold_body, crossvalid...</td>\n",
       "      <td>[statist_title, report_title, repeat_title, cr...</td>\n",
       "      <td>[crossvalid_tags]</td>\n",
       "      <td>[time_body, repeat_body, fold_body, crossvalid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487075</td>\n",
       "      <td>0</td>\n",
       "      <td>[dataset_body, mm_body, record_body, around_bo...</td>\n",
       "      <td>[binari_title, classif_title, imbalanc_title, ...</td>\n",
       "      <td>[unbalancedclass_tags, calibr_tags]</td>\n",
       "      <td>[dataset_body, mm_body, record_body, around_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481670</td>\n",
       "      <td>2</td>\n",
       "      <td>[want_body, run_body, regress_body, one_body, ...</td>\n",
       "      <td>[best_title, summar_title, likert_title, data_...</td>\n",
       "      <td>[multipleregress_tags, missingdata_tags, liker...</td>\n",
       "      <td>[want_body, run_body, regress_body, one_body, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  502641      1  [im_body, master_body, student_body, eec_body,...   \n",
       "1  477291      1  [know_body, good_body, question_body, found_bo...   \n",
       "2  448489      4  [time_body, repeat_body, fold_body, crossvalid...   \n",
       "3  487075      0  [dataset_body, mm_body, record_body, around_bo...   \n",
       "4  481670      2  [want_body, run_body, regress_body, one_body, ...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  [pytorch_title, tutori_title, dqn_title, defin...   \n",
       "1           [random_title, walk_title, memori_title]   \n",
       "2  [statist_title, report_title, repeat_title, cr...   \n",
       "3  [binari_title, classif_title, imbalanc_title, ...   \n",
       "4  [best_title, summar_title, likert_title, data_...   \n",
       "\n",
       "                                                Tags  \\\n",
       "0  [machinelearn_tags, reinforcementlearn_tags, q...   \n",
       "1                [probabl_tags, lawoflargenumb_tags]   \n",
       "2                                  [crossvalid_tags]   \n",
       "3                [unbalancedclass_tags, calibr_tags]   \n",
       "4  [multipleregress_tags, missingdata_tags, liker...   \n",
       "\n",
       "                                                text  \n",
       "0  [im_body, master_body, student_body, eec_body,...  \n",
       "1  [know_body, good_body, question_body, found_bo...  \n",
       "2  [time_body, repeat_body, fold_body, crossvalid...  \n",
       "3  [dataset_body, mm_body, record_body, around_bo...  \n",
       "4  [want_body, run_body, regress_body, one_body, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4esXb6WGuvmo"
   },
   "source": [
    "### Q. Detokenize and convert to document term matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JwhJ1pVBuvmo"
   },
   "outputs": [],
   "source": [
    "#Merge Three text column into one column and detokenize\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = df['text'].apply(TreebankWordDetokenizer().detokenize)\n",
    "countvec = CountVectorizer(min_df=0.05)\n",
    "sparse_dtm = countvec.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1668128857596,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "hiK01v4luvmp",
    "outputId": "f6521cdc-fd1a-446f-9a7c-eb03df04a5f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghitaalami/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Convert the sparse dtm to pandas DataFrame.\n",
    "dtm = pd.DataFrame(sparse_dtm.toarray(), columns=countvec.get_feature_names(), index=text.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZVDS6druvmq"
   },
   "source": [
    "### Q. Change dependent variable to binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DSQu_SPquvmq"
   },
   "outputs": [],
   "source": [
    "#Change 'Score' to a binary variable, which indicates whether the question is good or not.\n",
    "y = np.where(df['Score'] > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "kWhfmKlYuvmr"
   },
   "outputs": [],
   "source": [
    "#Add y_train and y_test to your data frame if it is needed. Drop unnecessary columns\n",
    "df['y'] = y\n",
    "df.drop(columns = ['Score'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiYas_A6JcS1"
   },
   "source": [
    "## Let's check our DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "WeTgM0ZMJqbI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502641</td>\n",
       "      <td>[im_body, master_body, student_body, eec_body,...</td>\n",
       "      <td>[pytorch_title, tutori_title, dqn_title, defin...</td>\n",
       "      <td>[machinelearn_tags, reinforcementlearn_tags, q...</td>\n",
       "      <td>[im_body, master_body, student_body, eec_body,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477291</td>\n",
       "      <td>[know_body, good_body, question_body, found_bo...</td>\n",
       "      <td>[random_title, walk_title, memori_title]</td>\n",
       "      <td>[probabl_tags, lawoflargenumb_tags]</td>\n",
       "      <td>[know_body, good_body, question_body, found_bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448489</td>\n",
       "      <td>[time_body, repeat_body, fold_body, crossvalid...</td>\n",
       "      <td>[statist_title, report_title, repeat_title, cr...</td>\n",
       "      <td>[crossvalid_tags]</td>\n",
       "      <td>[time_body, repeat_body, fold_body, crossvalid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487075</td>\n",
       "      <td>[dataset_body, mm_body, record_body, around_bo...</td>\n",
       "      <td>[binari_title, classif_title, imbalanc_title, ...</td>\n",
       "      <td>[unbalancedclass_tags, calibr_tags]</td>\n",
       "      <td>[dataset_body, mm_body, record_body, around_bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481670</td>\n",
       "      <td>[want_body, run_body, regress_body, one_body, ...</td>\n",
       "      <td>[best_title, summar_title, likert_title, data_...</td>\n",
       "      <td>[multipleregress_tags, missingdata_tags, liker...</td>\n",
       "      <td>[want_body, run_body, regress_body, one_body, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                               Body  \\\n",
       "0  502641  [im_body, master_body, student_body, eec_body,...   \n",
       "1  477291  [know_body, good_body, question_body, found_bo...   \n",
       "2  448489  [time_body, repeat_body, fold_body, crossvalid...   \n",
       "3  487075  [dataset_body, mm_body, record_body, around_bo...   \n",
       "4  481670  [want_body, run_body, regress_body, one_body, ...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  [pytorch_title, tutori_title, dqn_title, defin...   \n",
       "1           [random_title, walk_title, memori_title]   \n",
       "2  [statist_title, report_title, repeat_title, cr...   \n",
       "3  [binari_title, classif_title, imbalanc_title, ...   \n",
       "4  [best_title, summar_title, likert_title, data_...   \n",
       "\n",
       "                                                Tags  \\\n",
       "0  [machinelearn_tags, reinforcementlearn_tags, q...   \n",
       "1                [probabl_tags, lawoflargenumb_tags]   \n",
       "2                                  [crossvalid_tags]   \n",
       "3                [unbalancedclass_tags, calibr_tags]   \n",
       "4  [multipleregress_tags, missingdata_tags, liker...   \n",
       "\n",
       "                                                text  y  \n",
       "0  [im_body, master_body, student_body, eec_body,...  1  \n",
       "1  [know_body, good_body, question_body, found_bo...  1  \n",
       "2  [time_body, repeat_body, fold_body, crossvalid...  1  \n",
       "3  [dataset_body, mm_body, record_body, around_bo...  0  \n",
       "4  [want_body, run_body, regress_body, one_body, ...  1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVPT48NRuvms"
   },
   "source": [
    "## (b) Please read the instruction carefully in the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define the X_train and X_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dtm\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try different models to classify the useful vs not useful questions of the dataset. First we will try a baseline model that always predicts that the question is not useful since it's the most likely (predominant) class.\n",
    "\n",
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3yD6xH8PzyoZ"
   },
   "outputs": [],
   "source": [
    "baseline_acc = 1-(sum(y_test)/len(y_test))\n",
    "baseline_TPR = 0\n",
    "baseline_FPR = 0\n",
    "baseline_PRE = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a Logistic Regression (first classification model we saw in class). \n",
    "\n",
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "logreg = LogisticRegression(random_state=2)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_prob = logreg.predict_proba(X_test)\n",
    "y_pred = pd.Series([1 if x > 0.5 else 0 for x in y_prob[:,1]])\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "log_TPR = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "log_FPR = cm[0,1]/(cm[0,0]+cm[0,1])\n",
    "log_PRE = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "log_acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(min_samples_leaf=5, \n",
    "                             ccp_alpha=0.001,\n",
    "                             random_state = 2)\n",
    "\n",
    "\n",
    "dtc = dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and evaluate \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_dtc)\n",
    "dtc_TPR = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "dtc_FPR = cm[0,1]/(cm[0,0]+cm[0,1])\n",
    "dtc_PRE = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "dtc_acc = accuracy_score(y_test, y_pred_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features=6, min_samples_leaf=10, n_estimators=500, random_state=2)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "rf_TPR = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "rf_FPR = cm[0,1]/(cm[0,0]+cm[0,1])\n",
    "rf_PRE = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_lda)\n",
    "lda_TPR = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "lda_FPR = cm[0,1]/(cm[0,0]+cm[0,1])\n",
    "lda_PRE = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "lda_acc = accuracy_score(y_test, y_pred_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-O3EsbQGU0uX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>PRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.50588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.569766</td>\n",
       "      <td>0.479637</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>0.577889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.538005</td>\n",
       "      <td>0.237733</td>\n",
       "      <td>0.168704</td>\n",
       "      <td>0.579199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest with CV</th>\n",
       "      <td>0.57013</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.361371</td>\n",
       "      <td>0.574732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Discriminant Analysis</th>\n",
       "      <td>0.571221</td>\n",
       "      <td>0.473749</td>\n",
       "      <td>0.333573</td>\n",
       "      <td>0.581101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Accuracy       TPR       FPR       PRE\n",
       "Baseline                       0.50588         0         0      None\n",
       "Logistic Regression           0.569766  0.479637    0.3422  0.577889\n",
       "Decision Tree Classifier      0.538005  0.237733  0.168704  0.579199\n",
       "Random Forest with CV          0.57013       0.5  0.361371  0.574732\n",
       "Linear Discriminant Analysis  0.571221  0.473749  0.333573  0.581101"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Comparison Table\n",
    "#These lines are provided for you to help construct a comparison table.\n",
    "#It is not requred to follow this format. + You need to find ACC, TPR, FPR, PRE for each model that you choose.\n",
    "comparison_data = {'Baseline':[baseline_acc,baseline_TPR,baseline_FPR, baseline_PRE],\n",
    "                   'Logistic Regression':[log_acc,log_TPR,log_FPR, log_PRE],\n",
    "                   'Decision Tree Classifier':[dtc_acc,dtc_TPR,dtc_FPR,dtc_PRE],\n",
    "                   'Random Forest with CV':[rf_acc,rf_TPR, rf_FPR,rf_PRE],\n",
    "                  'Linear Discriminant Analysis':[lda_acc,lda_TPR, lda_FPR,lda_PRE]}\n",
    "\n",
    "comparison_table = pd.DataFrame(data=comparison_data, index=['Accuracy', 'TPR', 'FPR','PRE']).transpose()\n",
    "comparison_table.style.set_properties(**{'font-size': '12pt',}).set_table_styles([{'selector': 'th', 'props': [('font-size', '10pt')]}])\n",
    "comparison_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mjsc7lf6zOms"
   },
   "source": [
    "\n",
    "### Report details of your training procedures and final comparisons on the test set in this cell. Use your best judgment to choose a final model and explain your choice.\n",
    "\n",
    "The model that has the highest metrics is LDA, closely followed by the RF. \n",
    "Since LDA is better for multiclass classification under strong assumptions (independence and same sd accross features), since I cannot guarantee that those assumptions are met, I would chose the RF which is more interpretable. It also has a higher TPR and FPR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "XLa-KDajuvmz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR mean:  0.501 \n",
      "Confidence Interval: [ [0.484, 0.513] ]\n",
      "\n",
      "FPR mean:  0.43 \n",
      "Confidence Interval: [ [0.419, 0.439] ]\n",
      "\n",
      "Precision mean:  0.576 \n",
      "Confidence Interval: [ [0.56, 0.591] ]\n",
      "\n",
      "Accuracy mean:  0.57 \n",
      "Confidence Interval: [ [0.557, 0.579] ]\n"
     ]
    }
   ],
   "source": [
    "# Report Bootstrap Analysis \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "def bootstrap_metrics(X, y, model, metric, n_bootstrap=50, alpha=0.05):\n",
    "      n_samples = len(X)\n",
    "      results = np.zeros((n_bootstrap, 1))\n",
    "      for i in range(n_bootstrap):\n",
    "            indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "            X_boot = X.iloc[indices]\n",
    "            y_boot = y[np.array(indices)]\n",
    "            y_pred = model.predict(X_boot)\n",
    "            results[i, :] = metric(y_boot, y_pred)\n",
    "      ci_lower = np.percentile(results, 100*(alpha/2), axis=0)\n",
    "      ci_upper = np.percentile(results, 100*(1-alpha/2), axis=0)\n",
    "      average = np.mean(results)\n",
    "      return(ci_lower, ci_upper, average)\n",
    "\n",
    "def fpr(y_boot, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr =fp/(fp+tn)\n",
    "    return(fpr)\n",
    "\n",
    "ci_tpr = bootstrap_metrics(X_test, y_test, rf, recall_score)\n",
    "ci_fpr = bootstrap_metrics(X_test, y_test, rf, fpr)\n",
    "ci_pre = bootstrap_metrics(X_test, y_test, rf, precision_score)\n",
    "ci_acc = bootstrap_metrics(X_test, y_test, rf, accuracy_score)\n",
    "\n",
    "# Print the confidence intervals\n",
    "print(\"TPR mean: \", round(float(ci_tpr[2]),3), \"\\nConfidence Interval: \",\n",
    "      list([round(float(ci_tpr[0]),3), round(float(ci_tpr[1]),3)]), \"\\n\")\n",
    "print(\"FPR mean: \", round(float(ci_fpr[2]),3), \"\\nConfidence Interval: \",\n",
    "      list([round(float(ci_fpr[0]),3), round(float(ci_fpr[1]),3)]), \"\\n\")\n",
    "print(\"Precision mean: \", round(float(ci_pre[2]),3), \"\\nConfidence Interval: \",\n",
    "      list([round(float(ci_pre[0]),3), round(float(ci_pre[1]),3)]), \"\\n\")\n",
    "print(\"Accuracy mean: \", round(float(ci_acc[2]),3), \"\\nConfidence Interval: \",\n",
    "      list([round(float(ci_acc[0]),3), round(float(ci_acc[1]),3)]), \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrCM_96Quvm2"
   },
   "source": [
    "### (c)\n",
    "We would like to maximize the probability that the top question is useful. This means that if our model has a low true positive rate, it might be very detrimental, way more than if it has a high false positive rate. We want our model to be precise, this is why the metric I would use is precision. \n",
    "All my models have a very similar precision, with LDA being slightly better. \n",
    "I notice that it's a different model than I chose in the previous question (for interpretabiity reasons).\n",
    "On average, the probability of the baseline to display a useful question is simply the rate of useful questions in the dataset: around 49%. \n",
    "We thus have an improvement of around 9% on our model using LDA. \n",
    "It is a good start but I am sure I can improve the task more through hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uh2mvNrrTFBU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1AHr2NIU61Oco-PfG10o3gAYXLrsyJ8Sv",
     "timestamp": 1668122684758
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a05f4eab8a48e0fb699a9c4d2ff5136ad6fe08181e3a510e3ac6da38970e2134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
